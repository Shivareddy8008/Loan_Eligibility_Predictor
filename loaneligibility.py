# -*- coding: utf-8 -*-
"""LoanEligibility.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wng4li-nPAXIZtLgiH9naXCaDnx5AIX1
"""

import pandas as pd

# Load the dataset
df = pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')

# Display the first few rows of the dataframe
display(df.head())

# Check for missing values
print("Missing values before handling:")
display(df.isnull().sum())

# Handle missing values for numerical columns with the median
numerical_cols = df.select_dtypes(include=['number']).columns
for col in numerical_cols:
    df[col] = df[col].fillna(df[col].median())

# Handle missing values for categorical columns with the mode
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

print("\nMissing values after handling:")
display(df.isnull().sum())

# Encode categorical features
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Display the first few rows of the preprocessed dataframe
print("\nPreprocessed data:")
display(df.head())

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Separate features (X) and target (y)
X = df.drop('Loan_Status_Y', axis=1)
y = df['Loan_Status_Y']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train Logistic Regression model
log_reg_model = LogisticRegression(max_iter=1000)  # Increased max_iter
log_reg_model.fit(X_train, y_train)

# Initialize and train Random Forest model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

print("Models trained successfully.")

from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns

# Evaluate Logistic Regression model
y_pred_lr = log_reg_model.predict(X_test)
y_prob_lr = log_reg_model.predict_proba(X_test)[:, 1]

print("Logistic Regression Model Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))
print("ROC AUC Score:", roc_auc_score(y_test, y_prob_lr))

# Plot ROC curve for Logistic Regression
fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_prob_lr)
plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_score(y_test, y_prob_lr):.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()


# Evaluate Random Forest model
y_pred_rf = rf_model.predict(X_test)
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]

print("\nRandom Forest Model Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("ROC AUC Score:", roc_auc_score(y_test, y_prob_rf))

# Plot ROC curve for Random Forest
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf)
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_score(y_test, y_prob_rf):.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

!pip install gradio -q

import gradio as gr
import numpy as np

def predict_loan_eligibility(model_choice, gender, married, dependents, education, self_employed, applicant_income, coapplicant_income, loan_amount, loan_amount_term, credit_history, property_area):
    # Create a dictionary with the input values
    input_data = {
        'Gender': gender,
        'Married': married,
        'Dependents': dependents,
        'Education': education,
        'Self_Employed': self_employed,
        'ApplicantIncome': applicant_income,
        'CoapplicantIncome': coapplicant_income,
        'LoanAmount': loan_amount,
        'Loan_Amount_Term': loan_amount_term,
        'Credit_History': credit_history,
        'Property_Area': property_area
    }

    # Create a DataFrame from the input data
    input_df = pd.DataFrame([input_data])

    # Preprocess the input data (same steps as training data)
    # Handle missing values (although Gradio inputs are usually not missing, this is good practice)
    for col in numerical_cols:
        input_df[col] = input_df[col].fillna(df[col].median())
    for col in categorical_cols:
         input_df[col] = input_df[col].fillna(df[col].mode()[0])

    # Encode categorical features - ensure all possible columns from training are present
    input_df = pd.get_dummies(input_df, columns=categorical_cols, drop_first=True)

    # Reindex the input_df to match the columns of the training data (X_train)
    # This is crucial to ensure the model receives inputs in the correct order and with all expected features
    for col in X_train.columns:
        if col not in input_df.columns:
            input_df[col] = False # Add missing columns with a default value (False for one-hot encoded)

    input_df = input_df[X_train.columns]


    # Make prediction based on model choice
    if model_choice == "Logistic Regression":
        prediction = log_reg_model.predict(input_df)[0]
        probability = log_reg_model.predict_proba(input_df)[:, 1][0]
    else: # Random Forest
        prediction = rf_model.predict(input_df)[0]
        probability = rf_model.predict_proba(input_df)[:, 1][0]

    loan_status = "Approved" if prediction else "Rejected"
    return f"Loan Status: {loan_status} (Probability: {probability:.2f})"

# Get the categories for the dropdowns from the original dataframe before one-hot encoding
original_df = pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv') # Load original data again to get categories

gender_options = original_df['Gender'].dropna().unique().tolist()
married_options = original_df['Married'].dropna().unique().tolist()
dependents_options = original_df['Dependents'].dropna().unique().tolist()
education_options = original_df['Education'].dropna().unique().tolist()
self_employed_options = original_df['Self_Employed'].dropna().unique().tolist()
property_area_options = original_df['Property_Area'].dropna().unique().tolist()
credit_history_options = sorted(original_df['Credit_History'].dropna().unique().tolist())


# Create Gradio interface
interface = gr.Interface(
    fn=predict_loan_eligibility,
    inputs=[
        gr.Radio(["Logistic Regression", "Random Forest"], label="Select Model"),
        gr.Dropdown(gender_options, label="Gender"),
        gr.Dropdown(married_options, label="Married"),
        gr.Dropdown(dependents_options, label="Dependents"),
        gr.Dropdown(education_options, label="Education"),
        gr.Dropdown(self_employed_options, label="Self Employed"),
        gr.Number(label="Applicant Income"),
        gr.Number(label="Coapplicant Income"),
        gr.Number(label="Loan Amount"),
        gr.Number(label="Loan Amount Term"),
        gr.Dropdown(credit_history_options, label="Credit History"),
        gr.Dropdown(property_area_options, label="Property Area")
    ],
    outputs="text",
    title="Loan Eligibility Predictor",
    description="Enter applicant details to predict loan eligibility using Logistic Regression or Random Forest models."
)

interface.launch(debug=True)